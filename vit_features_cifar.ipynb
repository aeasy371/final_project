{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/miniconda3/envs/Crypten/lib/python3.7/site-packages/transformers/models/vit/feature_extraction_vit.py:31: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  FutureWarning,\n",
      "Some weights of the model checkpoint at microsoft/swin-tiny-patch4-window7-224 were not used when initializing SwinModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing SwinModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SwinModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 782/782 [00:57<00:00, 13.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features to cifar10_swin_features.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/swin-tiny-patch4-window7-224 were not used when initializing SwinModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing SwinModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SwinModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 782/782 [00:57<00:00, 13.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features to cifar100_swin_features.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from transformers import AutoFeatureExtractor, SwinModel\n",
    "from PIL import Image\n",
    "# from timm import create_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_featureset(dataset_name: str):\n",
    "\t# Parameters\n",
    "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\tbatch_size = 64\n",
    "\tsave_path = f\"{dataset_name}_swin_features.pt\"\n",
    "\n",
    "\t# Load HuggingFace Swin\n",
    "\tmodel_name = \"microsoft/swin-tiny-patch4-window7-224\"\n",
    "\textractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "\tmodel = SwinModel.from_pretrained(model_name)\n",
    "\tmodel.eval().to(device)\n",
    "\n",
    "\t# Typical ViT preprocessing (same as Hugging Face ViT config)\n",
    "\ttransform = transforms.Compose([\n",
    "\t\ttransforms.Resize(224),\n",
    "\t\ttransforms.ToTensor(),\n",
    "\t\ttransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\t])\n",
    "\n",
    "\n",
    "\t# Load CIFAR dataset\n",
    "\tif dataset_name == 'cifar10':\n",
    "\t\tdataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\telif dataset_name == 'cifar100':\n",
    "\t\tdataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "\tdataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\t# Store features + labels\n",
    "\tall_features = []\n",
    "\tall_labels = []\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tfor imgs, labels in tqdm(dataloader):\n",
    "\t\t\timgs = imgs.to(device)\n",
    "\t\t\tfeatures = model(imgs)\n",
    "\t\t\tfeatures = features.pooler_output\n",
    "\t\t\tall_features.append(features.cpu())\n",
    "\t\t\tall_labels.append(labels)\n",
    "\n",
    "\t# Save to file\n",
    "\tfeatures_tensor = torch.cat(all_features)\n",
    "\tlabels_tensor = torch.cat(all_labels)\n",
    "\ttorch.save({'features': features_tensor, 'labels': labels_tensor}, save_path)\n",
    "\n",
    "\tprint(f\"Saved features to {save_path}\")\n",
    "\n",
    "\n",
    "create_featureset('cifar10')\n",
    "create_featureset('cifar100')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# print(torch.cuda.is_available())  # This should return True if CUDA is available\n",
    "# print(torch.cuda.current_device())  # This prints the current GPU device index\n",
    "# print(torch.cuda.get_device_name(0))  # This should print your GPU model name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) tensor(99)\n",
      "Epoch 1: Train Loss = 3.3888, Train Acc = 40.52% | Val Loss = 2.4643, Val Acc = 59.14%\n",
      "Epoch 2: Train Loss = 1.9920, Train Acc = 63.81% | Val Loss = 1.7087, Val Acc = 65.22%\n",
      "Epoch 3: Train Loss = 1.5147, Train Acc = 67.80% | Val Loss = 1.4208, Val Acc = 67.16%\n",
      "Epoch 4: Train Loss = 1.3054, Train Acc = 69.80% | Val Loss = 1.2755, Val Acc = 68.26%\n",
      "Epoch 5: Train Loss = 1.1867, Train Acc = 71.15% | Val Loss = 1.1863, Val Acc = 69.78%\n",
      "Epoch 6: Train Loss = 1.1081, Train Acc = 72.33% | Val Loss = 1.1258, Val Acc = 70.84%\n",
      "Epoch 7: Train Loss = 1.0508, Train Acc = 73.06% | Val Loss = 1.0807, Val Acc = 71.18%\n",
      "Epoch 8: Train Loss = 1.0061, Train Acc = 73.78% | Val Loss = 1.0464, Val Acc = 71.92%\n",
      "Epoch 9: Train Loss = 0.9702, Train Acc = 74.47% | Val Loss = 1.0191, Val Acc = 71.92%\n",
      "Epoch 10: Train Loss = 0.9402, Train Acc = 75.06% | Val Loss = 0.9962, Val Acc = 72.44%\n",
      "Epoch 11: Train Loss = 0.9143, Train Acc = 75.49% | Val Loss = 0.9785, Val Acc = 72.78%\n",
      "Epoch 12: Train Loss = 0.8920, Train Acc = 75.89% | Val Loss = 0.9615, Val Acc = 73.08%\n",
      "Epoch 13: Train Loss = 0.8721, Train Acc = 76.40% | Val Loss = 0.9466, Val Acc = 73.54%\n",
      "Epoch 14: Train Loss = 0.8541, Train Acc = 76.70% | Val Loss = 0.9358, Val Acc = 73.66%\n",
      "Epoch 15: Train Loss = 0.8381, Train Acc = 77.05% | Val Loss = 0.9240, Val Acc = 74.14%\n",
      "Epoch 16: Train Loss = 0.8232, Train Acc = 77.29% | Val Loss = 0.9156, Val Acc = 74.22%\n",
      "Epoch 17: Train Loss = 0.8096, Train Acc = 77.59% | Val Loss = 0.9058, Val Acc = 74.58%\n",
      "Epoch 18: Train Loss = 0.7970, Train Acc = 77.93% | Val Loss = 0.8984, Val Acc = 74.58%\n",
      "Epoch 19: Train Loss = 0.7853, Train Acc = 78.15% | Val Loss = 0.8907, Val Acc = 75.06%\n",
      "Epoch 20: Train Loss = 0.7743, Train Acc = 78.48% | Val Loss = 0.8850, Val Acc = 74.98%\n",
      "Epoch 21: Train Loss = 0.7641, Train Acc = 78.61% | Val Loss = 0.8784, Val Acc = 75.18%\n",
      "Epoch 22: Train Loss = 0.7542, Train Acc = 78.97% | Val Loss = 0.8733, Val Acc = 75.42%\n",
      "Epoch 23: Train Loss = 0.7449, Train Acc = 79.09% | Val Loss = 0.8674, Val Acc = 75.66%\n",
      "Epoch 24: Train Loss = 0.7363, Train Acc = 79.28% | Val Loss = 0.8629, Val Acc = 75.78%\n",
      "Epoch 25: Train Loss = 0.7279, Train Acc = 79.59% | Val Loss = 0.8584, Val Acc = 75.76%\n",
      "Epoch 26: Train Loss = 0.7199, Train Acc = 79.75% | Val Loss = 0.8548, Val Acc = 75.74%\n",
      "Epoch 27: Train Loss = 0.7123, Train Acc = 79.98% | Val Loss = 0.8510, Val Acc = 76.02%\n",
      "Epoch 28: Train Loss = 0.7051, Train Acc = 80.16% | Val Loss = 0.8478, Val Acc = 75.90%\n",
      "Epoch 29: Train Loss = 0.6980, Train Acc = 80.41% | Val Loss = 0.8448, Val Acc = 75.92%\n",
      "Epoch 30: Train Loss = 0.6913, Train Acc = 80.53% | Val Loss = 0.8403, Val Acc = 76.18%\n",
      "Epoch 31: Train Loss = 0.6849, Train Acc = 80.75% | Val Loss = 0.8371, Val Acc = 76.06%\n",
      "Epoch 32: Train Loss = 0.6787, Train Acc = 80.96% | Val Loss = 0.8350, Val Acc = 76.28%\n",
      "Epoch 33: Train Loss = 0.6726, Train Acc = 81.02% | Val Loss = 0.8329, Val Acc = 76.22%\n",
      "Epoch 34: Train Loss = 0.6669, Train Acc = 81.21% | Val Loss = 0.8305, Val Acc = 76.48%\n",
      "Epoch 35: Train Loss = 0.6612, Train Acc = 81.33% | Val Loss = 0.8286, Val Acc = 76.20%\n",
      "Epoch 36: Train Loss = 0.6558, Train Acc = 81.55% | Val Loss = 0.8259, Val Acc = 76.38%\n",
      "Epoch 37: Train Loss = 0.6504, Train Acc = 81.62% | Val Loss = 0.8232, Val Acc = 76.44%\n",
      "Epoch 38: Train Loss = 0.6453, Train Acc = 81.83% | Val Loss = 0.8220, Val Acc = 76.42%\n",
      "Epoch 39: Train Loss = 0.6403, Train Acc = 81.98% | Val Loss = 0.8206, Val Acc = 76.48%\n",
      "Epoch 40: Train Loss = 0.6355, Train Acc = 82.16% | Val Loss = 0.8182, Val Acc = 76.62%\n",
      "Epoch 41: Train Loss = 0.6308, Train Acc = 82.20% | Val Loss = 0.8168, Val Acc = 76.54%\n",
      "Epoch 42: Train Loss = 0.6261, Train Acc = 82.40% | Val Loss = 0.8152, Val Acc = 76.46%\n",
      "Epoch 43: Train Loss = 0.6217, Train Acc = 82.50% | Val Loss = 0.8135, Val Acc = 76.64%\n",
      "Epoch 44: Train Loss = 0.6173, Train Acc = 82.69% | Val Loss = 0.8117, Val Acc = 76.54%\n",
      "Epoch 45: Train Loss = 0.6131, Train Acc = 82.77% | Val Loss = 0.8117, Val Acc = 76.56%\n",
      "Epoch 46: Train Loss = 0.6089, Train Acc = 82.85% | Val Loss = 0.8092, Val Acc = 76.50%\n",
      "Epoch 47: Train Loss = 0.6048, Train Acc = 83.01% | Val Loss = 0.8074, Val Acc = 76.70%\n",
      "Epoch 48: Train Loss = 0.6009, Train Acc = 83.11% | Val Loss = 0.8065, Val Acc = 76.52%\n",
      "Epoch 49: Train Loss = 0.5970, Train Acc = 83.22% | Val Loss = 0.8059, Val Acc = 76.78%\n",
      "Epoch 50: Train Loss = 0.5933, Train Acc = 83.38% | Val Loss = 0.8049, Val Acc = 76.62%\n",
      "Epoch 51: Train Loss = 0.5894, Train Acc = 83.47% | Val Loss = 0.8037, Val Acc = 76.66%\n",
      "Epoch 52: Train Loss = 0.5859, Train Acc = 83.66% | Val Loss = 0.8037, Val Acc = 76.74%\n",
      "Epoch 53: Train Loss = 0.5822, Train Acc = 83.71% | Val Loss = 0.8024, Val Acc = 76.60%\n",
      "Epoch 54: Train Loss = 0.5789, Train Acc = 83.80% | Val Loss = 0.8015, Val Acc = 76.82%\n",
      "Epoch 55: Train Loss = 0.5754, Train Acc = 83.83% | Val Loss = 0.8004, Val Acc = 76.68%\n",
      "Epoch 56: Train Loss = 0.5721, Train Acc = 83.94% | Val Loss = 0.8004, Val Acc = 76.70%\n",
      "Epoch 57: Train Loss = 0.5687, Train Acc = 84.07% | Val Loss = 0.7985, Val Acc = 76.66%\n",
      "Epoch 58: Train Loss = 0.5656, Train Acc = 84.11% | Val Loss = 0.7976, Val Acc = 76.84%\n",
      "Epoch 59: Train Loss = 0.5623, Train Acc = 84.26% | Val Loss = 0.7971, Val Acc = 76.54%\n",
      "Epoch 60: Train Loss = 0.5592, Train Acc = 84.36% | Val Loss = 0.7966, Val Acc = 76.80%\n",
      "Epoch 61: Train Loss = 0.5562, Train Acc = 84.42% | Val Loss = 0.7962, Val Acc = 76.54%\n",
      "Epoch 62: Train Loss = 0.5532, Train Acc = 84.51% | Val Loss = 0.7956, Val Acc = 76.78%\n",
      "Epoch 63: Train Loss = 0.5502, Train Acc = 84.56% | Val Loss = 0.7953, Val Acc = 76.64%\n",
      "Epoch 64: Train Loss = 0.5473, Train Acc = 84.70% | Val Loss = 0.7947, Val Acc = 76.70%\n",
      "Epoch 65: Train Loss = 0.5444, Train Acc = 84.85% | Val Loss = 0.7941, Val Acc = 76.64%\n",
      "Epoch 66: Train Loss = 0.5417, Train Acc = 84.84% | Val Loss = 0.7935, Val Acc = 76.62%\n",
      "Epoch 67: Train Loss = 0.5389, Train Acc = 84.97% | Val Loss = 0.7931, Val Acc = 76.80%\n",
      "Epoch 68: Train Loss = 0.5361, Train Acc = 85.07% | Val Loss = 0.7921, Val Acc = 76.72%\n",
      "Epoch 69: Train Loss = 0.5335, Train Acc = 85.16% | Val Loss = 0.7924, Val Acc = 76.62%\n",
      "Epoch 70: Train Loss = 0.5308, Train Acc = 85.22% | Val Loss = 0.7914, Val Acc = 76.80%\n",
      "Epoch 71: Train Loss = 0.5282, Train Acc = 85.27% | Val Loss = 0.7910, Val Acc = 76.78%\n",
      "Epoch 72: Train Loss = 0.5257, Train Acc = 85.32% | Val Loss = 0.7908, Val Acc = 76.78%\n",
      "Epoch 73: Train Loss = 0.5232, Train Acc = 85.42% | Val Loss = 0.7904, Val Acc = 76.80%\n",
      "Epoch 74: Train Loss = 0.5207, Train Acc = 85.47% | Val Loss = 0.7893, Val Acc = 76.90%\n",
      "Epoch 75: Train Loss = 0.5182, Train Acc = 85.61% | Val Loss = 0.7902, Val Acc = 76.80%\n",
      "Epoch 76: Train Loss = 0.5158, Train Acc = 85.70% | Val Loss = 0.7891, Val Acc = 76.84%\n",
      "Epoch 77: Train Loss = 0.5135, Train Acc = 85.74% | Val Loss = 0.7895, Val Acc = 76.68%\n",
      "Epoch 78: Train Loss = 0.5111, Train Acc = 85.82% | Val Loss = 0.7888, Val Acc = 76.92%\n",
      "Epoch 79: Train Loss = 0.5088, Train Acc = 85.92% | Val Loss = 0.7886, Val Acc = 76.90%\n",
      "Epoch 80: Train Loss = 0.5065, Train Acc = 86.01% | Val Loss = 0.7883, Val Acc = 76.82%\n",
      "Epoch 81: Train Loss = 0.5043, Train Acc = 86.03% | Val Loss = 0.7879, Val Acc = 76.92%\n",
      "Epoch 82: Train Loss = 0.5021, Train Acc = 86.21% | Val Loss = 0.7879, Val Acc = 76.92%\n",
      "Epoch 83: Train Loss = 0.4998, Train Acc = 86.23% | Val Loss = 0.7881, Val Acc = 76.78%\n",
      "Epoch 84: Train Loss = 0.4978, Train Acc = 86.26% | Val Loss = 0.7872, Val Acc = 76.84%\n",
      "Epoch 85: Train Loss = 0.4956, Train Acc = 86.36% | Val Loss = 0.7871, Val Acc = 76.96%\n",
      "Epoch 86: Train Loss = 0.4935, Train Acc = 86.47% | Val Loss = 0.7877, Val Acc = 76.78%\n",
      "Epoch 87: Train Loss = 0.4914, Train Acc = 86.50% | Val Loss = 0.7870, Val Acc = 76.84%\n",
      "Epoch 88: Train Loss = 0.4894, Train Acc = 86.58% | Val Loss = 0.7865, Val Acc = 76.98%\n",
      "Epoch 89: Train Loss = 0.4873, Train Acc = 86.66% | Val Loss = 0.7862, Val Acc = 76.86%\n",
      "Epoch 90: Train Loss = 0.4853, Train Acc = 86.73% | Val Loss = 0.7869, Val Acc = 76.82%\n",
      "Epoch 91: Train Loss = 0.4835, Train Acc = 86.84% | Val Loss = 0.7869, Val Acc = 76.86%\n",
      "Epoch 92: Train Loss = 0.4814, Train Acc = 86.87% | Val Loss = 0.7864, Val Acc = 76.86%\n",
      "Epoch 93: Train Loss = 0.4794, Train Acc = 86.85% | Val Loss = 0.7865, Val Acc = 76.88%\n",
      "Epoch 94: Train Loss = 0.4776, Train Acc = 86.93% | Val Loss = 0.7863, Val Acc = 76.90%\n",
      "Epoch 95: Train Loss = 0.4757, Train Acc = 87.08% | Val Loss = 0.7864, Val Acc = 76.88%\n",
      "Epoch 96: Train Loss = 0.4737, Train Acc = 87.13% | Val Loss = 0.7856, Val Acc = 76.78%\n",
      "Epoch 97: Train Loss = 0.4719, Train Acc = 87.16% | Val Loss = 0.7855, Val Acc = 76.88%\n",
      "Epoch 98: Train Loss = 0.4701, Train Acc = 87.22% | Val Loss = 0.7861, Val Acc = 76.88%\n",
      "Epoch 99: Train Loss = 0.4683, Train Acc = 87.25% | Val Loss = 0.7860, Val Acc = 76.78%\n",
      "Epoch 100: Train Loss = 0.4665, Train Acc = 87.26% | Val Loss = 0.7859, Val Acc = 76.78%\n",
      "Epoch 101: Train Loss = 0.4647, Train Acc = 87.39% | Val Loss = 0.7862, Val Acc = 76.74%\n",
      "Epoch 102: Train Loss = 0.4630, Train Acc = 87.44% | Val Loss = 0.7856, Val Acc = 76.90%\n",
      "Epoch 103: Train Loss = 0.4613, Train Acc = 87.48% | Val Loss = 0.7857, Val Acc = 76.80%\n",
      "Epoch 104: Train Loss = 0.4595, Train Acc = 87.52% | Val Loss = 0.7867, Val Acc = 76.76%\n",
      "Epoch 105: Train Loss = 0.4578, Train Acc = 87.56% | Val Loss = 0.7858, Val Acc = 76.68%\n",
      "Epoch 106: Train Loss = 0.4562, Train Acc = 87.61% | Val Loss = 0.7856, Val Acc = 76.78%\n",
      "Epoch 107: Train Loss = 0.4544, Train Acc = 87.71% | Val Loss = 0.7856, Val Acc = 76.82%\n",
      "Epoch 108: Train Loss = 0.4529, Train Acc = 87.77% | Val Loss = 0.7853, Val Acc = 76.64%\n",
      "Epoch 109: Train Loss = 0.4513, Train Acc = 87.81% | Val Loss = 0.7859, Val Acc = 76.76%\n",
      "Epoch 110: Train Loss = 0.4497, Train Acc = 87.87% | Val Loss = 0.7860, Val Acc = 76.84%\n",
      "Epoch 111: Train Loss = 0.4480, Train Acc = 87.90% | Val Loss = 0.7866, Val Acc = 76.64%\n",
      "Epoch 112: Train Loss = 0.4464, Train Acc = 87.97% | Val Loss = 0.7864, Val Acc = 76.80%\n",
      "Epoch 113: Train Loss = 0.4449, Train Acc = 87.94% | Val Loss = 0.7865, Val Acc = 76.82%\n",
      "Epoch 114: Train Loss = 0.4434, Train Acc = 88.03% | Val Loss = 0.7871, Val Acc = 76.74%\n",
      "Epoch 115: Train Loss = 0.4418, Train Acc = 88.08% | Val Loss = 0.7866, Val Acc = 76.62%\n",
      "Epoch 116: Train Loss = 0.4403, Train Acc = 88.12% | Val Loss = 0.7869, Val Acc = 76.64%\n",
      "Epoch 117: Train Loss = 0.4388, Train Acc = 88.17% | Val Loss = 0.7860, Val Acc = 76.58%\n",
      "Epoch 118: Train Loss = 0.4373, Train Acc = 88.22% | Val Loss = 0.7865, Val Acc = 76.72%\n",
      "Epoch 119: Train Loss = 0.4359, Train Acc = 88.30% | Val Loss = 0.7866, Val Acc = 76.76%\n",
      "Epoch 120: Train Loss = 0.4344, Train Acc = 88.35% | Val Loss = 0.7867, Val Acc = 76.72%\n",
      "Epoch 121: Train Loss = 0.4329, Train Acc = 88.38% | Val Loss = 0.7870, Val Acc = 76.72%\n",
      "Epoch 122: Train Loss = 0.4315, Train Acc = 88.46% | Val Loss = 0.7872, Val Acc = 76.68%\n",
      "Epoch 123: Train Loss = 0.4301, Train Acc = 88.42% | Val Loss = 0.7870, Val Acc = 76.74%\n",
      "Epoch 124: Train Loss = 0.4287, Train Acc = 88.55% | Val Loss = 0.7868, Val Acc = 76.74%\n",
      "Epoch 125: Train Loss = 0.4272, Train Acc = 88.53% | Val Loss = 0.7871, Val Acc = 76.64%\n",
      "Epoch 126: Train Loss = 0.4258, Train Acc = 88.66% | Val Loss = 0.7875, Val Acc = 76.66%\n",
      "Epoch 127: Train Loss = 0.4245, Train Acc = 88.63% | Val Loss = 0.7874, Val Acc = 76.72%\n",
      "Epoch 128: Train Loss = 0.4231, Train Acc = 88.69% | Val Loss = 0.7874, Val Acc = 76.88%\n",
      "Epoch 129: Train Loss = 0.4218, Train Acc = 88.76% | Val Loss = 0.7880, Val Acc = 76.74%\n",
      "Epoch 130: Train Loss = 0.4206, Train Acc = 88.81% | Val Loss = 0.7880, Val Acc = 76.74%\n",
      "Epoch 131: Train Loss = 0.4192, Train Acc = 88.87% | Val Loss = 0.7880, Val Acc = 76.68%\n",
      "Epoch 132: Train Loss = 0.4178, Train Acc = 88.90% | Val Loss = 0.7880, Val Acc = 76.80%\n",
      "Epoch 133: Train Loss = 0.4165, Train Acc = 88.93% | Val Loss = 0.7886, Val Acc = 76.66%\n",
      "Epoch 134: Train Loss = 0.4152, Train Acc = 89.00% | Val Loss = 0.7883, Val Acc = 76.76%\n",
      "Epoch 135: Train Loss = 0.4140, Train Acc = 89.11% | Val Loss = 0.7887, Val Acc = 76.66%\n",
      "Epoch 136: Train Loss = 0.4126, Train Acc = 89.10% | Val Loss = 0.7893, Val Acc = 76.66%\n",
      "Epoch 137: Train Loss = 0.4114, Train Acc = 89.16% | Val Loss = 0.7894, Val Acc = 76.78%\n",
      "Epoch 138: Train Loss = 0.4102, Train Acc = 89.21% | Val Loss = 0.7892, Val Acc = 76.54%\n",
      "Epoch 139: Train Loss = 0.4090, Train Acc = 89.20% | Val Loss = 0.7894, Val Acc = 76.58%\n",
      "Epoch 140: Train Loss = 0.4077, Train Acc = 89.25% | Val Loss = 0.7890, Val Acc = 76.74%\n",
      "Epoch 141: Train Loss = 0.4065, Train Acc = 89.33% | Val Loss = 0.7900, Val Acc = 76.78%\n",
      "Epoch 142: Train Loss = 0.4053, Train Acc = 89.38% | Val Loss = 0.7898, Val Acc = 76.76%\n",
      "Epoch 143: Train Loss = 0.4040, Train Acc = 89.48% | Val Loss = 0.7896, Val Acc = 76.62%\n",
      "Epoch 144: Train Loss = 0.4029, Train Acc = 89.46% | Val Loss = 0.7901, Val Acc = 76.84%\n",
      "Epoch 145: Train Loss = 0.4017, Train Acc = 89.54% | Val Loss = 0.7905, Val Acc = 76.84%\n",
      "Epoch 146: Train Loss = 0.4005, Train Acc = 89.59% | Val Loss = 0.7903, Val Acc = 77.00%\n",
      "Epoch 147: Train Loss = 0.3994, Train Acc = 89.54% | Val Loss = 0.7904, Val Acc = 76.82%\n",
      "Epoch 148: Train Loss = 0.3982, Train Acc = 89.52% | Val Loss = 0.7906, Val Acc = 76.80%\n",
      "Epoch 149: Train Loss = 0.3971, Train Acc = 89.66% | Val Loss = 0.7908, Val Acc = 76.88%\n",
      "Epoch 150: Train Loss = 0.3960, Train Acc = 89.72% | Val Loss = 0.7916, Val Acc = 76.72%\n",
      "Epoch 151: Train Loss = 0.3949, Train Acc = 89.73% | Val Loss = 0.7916, Val Acc = 76.82%\n",
      "Epoch 152: Train Loss = 0.3937, Train Acc = 89.71% | Val Loss = 0.7914, Val Acc = 76.92%\n",
      "Epoch 153: Train Loss = 0.3925, Train Acc = 89.78% | Val Loss = 0.7915, Val Acc = 76.86%\n",
      "Epoch 154: Train Loss = 0.3915, Train Acc = 89.86% | Val Loss = 0.7916, Val Acc = 76.90%\n",
      "Epoch 155: Train Loss = 0.3904, Train Acc = 89.86% | Val Loss = 0.7919, Val Acc = 76.80%\n",
      "Epoch 156: Train Loss = 0.3893, Train Acc = 89.87% | Val Loss = 0.7926, Val Acc = 76.76%\n",
      "Epoch 157: Train Loss = 0.3882, Train Acc = 89.94% | Val Loss = 0.7925, Val Acc = 76.90%\n",
      "Epoch 158: Train Loss = 0.3871, Train Acc = 89.93% | Val Loss = 0.7929, Val Acc = 76.86%\n",
      "Epoch 159: Train Loss = 0.3861, Train Acc = 89.97% | Val Loss = 0.7932, Val Acc = 76.92%\n",
      "Epoch 160: Train Loss = 0.3850, Train Acc = 90.00% | Val Loss = 0.7929, Val Acc = 76.86%\n",
      "Epoch 161: Train Loss = 0.3840, Train Acc = 90.03% | Val Loss = 0.7934, Val Acc = 76.68%\n",
      "Epoch 162: Train Loss = 0.3830, Train Acc = 90.07% | Val Loss = 0.7934, Val Acc = 76.92%\n",
      "Epoch 163: Train Loss = 0.3819, Train Acc = 90.13% | Val Loss = 0.7940, Val Acc = 76.64%\n",
      "Epoch 164: Train Loss = 0.3808, Train Acc = 90.13% | Val Loss = 0.7941, Val Acc = 76.90%\n",
      "Epoch 165: Train Loss = 0.3799, Train Acc = 90.14% | Val Loss = 0.7943, Val Acc = 76.86%\n",
      "Epoch 166: Train Loss = 0.3788, Train Acc = 90.22% | Val Loss = 0.7941, Val Acc = 76.84%\n",
      "Epoch 167: Train Loss = 0.3779, Train Acc = 90.24% | Val Loss = 0.7947, Val Acc = 76.96%\n",
      "Epoch 168: Train Loss = 0.3768, Train Acc = 90.28% | Val Loss = 0.7949, Val Acc = 76.82%\n",
      "Epoch 169: Train Loss = 0.3759, Train Acc = 90.31% | Val Loss = 0.7951, Val Acc = 76.58%\n",
      "Epoch 170: Train Loss = 0.3748, Train Acc = 90.37% | Val Loss = 0.7953, Val Acc = 76.96%\n",
      "Epoch 171: Train Loss = 0.3739, Train Acc = 90.35% | Val Loss = 0.7953, Val Acc = 76.82%\n",
      "Epoch 172: Train Loss = 0.3728, Train Acc = 90.40% | Val Loss = 0.7961, Val Acc = 76.78%\n",
      "Epoch 173: Train Loss = 0.3719, Train Acc = 90.44% | Val Loss = 0.7960, Val Acc = 76.70%\n",
      "Epoch 174: Train Loss = 0.3710, Train Acc = 90.45% | Val Loss = 0.7965, Val Acc = 76.64%\n",
      "Epoch 175: Train Loss = 0.3700, Train Acc = 90.47% | Val Loss = 0.7971, Val Acc = 76.72%\n",
      "Epoch 176: Train Loss = 0.3691, Train Acc = 90.53% | Val Loss = 0.7965, Val Acc = 76.78%\n",
      "Epoch 177: Train Loss = 0.3681, Train Acc = 90.56% | Val Loss = 0.7968, Val Acc = 76.76%\n",
      "Epoch 178: Train Loss = 0.3672, Train Acc = 90.61% | Val Loss = 0.7974, Val Acc = 76.80%\n",
      "Epoch 179: Train Loss = 0.3663, Train Acc = 90.67% | Val Loss = 0.7976, Val Acc = 76.74%\n",
      "Epoch 180: Train Loss = 0.3654, Train Acc = 90.66% | Val Loss = 0.7979, Val Acc = 76.68%\n",
      "Epoch 181: Train Loss = 0.3644, Train Acc = 90.70% | Val Loss = 0.7979, Val Acc = 76.76%\n",
      "Epoch 182: Train Loss = 0.3635, Train Acc = 90.67% | Val Loss = 0.7977, Val Acc = 76.70%\n",
      "Epoch 183: Train Loss = 0.3626, Train Acc = 90.76% | Val Loss = 0.7985, Val Acc = 76.72%\n",
      "Epoch 184: Train Loss = 0.3618, Train Acc = 90.75% | Val Loss = 0.7985, Val Acc = 76.62%\n",
      "Epoch 185: Train Loss = 0.3608, Train Acc = 90.77% | Val Loss = 0.7986, Val Acc = 76.70%\n",
      "Epoch 186: Train Loss = 0.3600, Train Acc = 90.82% | Val Loss = 0.7987, Val Acc = 76.66%\n",
      "Epoch 187: Train Loss = 0.3590, Train Acc = 90.86% | Val Loss = 0.7995, Val Acc = 76.66%\n",
      "Epoch 188: Train Loss = 0.3581, Train Acc = 90.82% | Val Loss = 0.8004, Val Acc = 76.66%\n",
      "Epoch 189: Train Loss = 0.3573, Train Acc = 90.90% | Val Loss = 0.8000, Val Acc = 76.60%\n",
      "Epoch 190: Train Loss = 0.3564, Train Acc = 90.92% | Val Loss = 0.8004, Val Acc = 76.66%\n",
      "Epoch 191: Train Loss = 0.3555, Train Acc = 90.99% | Val Loss = 0.8003, Val Acc = 76.74%\n",
      "Epoch 192: Train Loss = 0.3548, Train Acc = 91.02% | Val Loss = 0.8003, Val Acc = 76.60%\n",
      "Epoch 193: Train Loss = 0.3538, Train Acc = 91.06% | Val Loss = 0.8009, Val Acc = 76.60%\n",
      "Epoch 194: Train Loss = 0.3530, Train Acc = 91.09% | Val Loss = 0.8008, Val Acc = 76.68%\n",
      "Epoch 195: Train Loss = 0.3522, Train Acc = 91.07% | Val Loss = 0.8012, Val Acc = 76.56%\n",
      "Epoch 196: Train Loss = 0.3513, Train Acc = 91.08% | Val Loss = 0.8017, Val Acc = 76.72%\n",
      "Epoch 197: Train Loss = 0.3505, Train Acc = 91.17% | Val Loss = 0.8015, Val Acc = 76.56%\n",
      "Epoch 198: Train Loss = 0.3497, Train Acc = 91.19% | Val Loss = 0.8021, Val Acc = 76.76%\n",
      "Epoch 199: Train Loss = 0.3489, Train Acc = 91.19% | Val Loss = 0.8023, Val Acc = 76.60%\n",
      "Epoch 200: Train Loss = 0.3480, Train Acc = 91.26% | Val Loss = 0.8027, Val Acc = 76.56%\n",
      "Epoch 201: Train Loss = 0.3472, Train Acc = 91.27% | Val Loss = 0.8031, Val Acc = 76.62%\n",
      "Epoch 202: Train Loss = 0.3464, Train Acc = 91.31% | Val Loss = 0.8029, Val Acc = 76.56%\n",
      "Epoch 203: Train Loss = 0.3457, Train Acc = 91.31% | Val Loss = 0.8037, Val Acc = 76.74%\n",
      "Epoch 204: Train Loss = 0.3448, Train Acc = 91.34% | Val Loss = 0.8043, Val Acc = 76.64%\n",
      "Epoch 205: Train Loss = 0.3440, Train Acc = 91.38% | Val Loss = 0.8041, Val Acc = 76.66%\n",
      "Epoch 206: Train Loss = 0.3432, Train Acc = 91.40% | Val Loss = 0.8042, Val Acc = 76.52%\n",
      "Epoch 207: Train Loss = 0.3424, Train Acc = 91.41% | Val Loss = 0.8047, Val Acc = 76.58%\n",
      "Epoch 208: Train Loss = 0.3417, Train Acc = 91.44% | Val Loss = 0.8046, Val Acc = 76.66%\n",
      "Epoch 209: Train Loss = 0.3409, Train Acc = 91.47% | Val Loss = 0.8048, Val Acc = 76.54%\n",
      "Epoch 210: Train Loss = 0.3402, Train Acc = 91.45% | Val Loss = 0.8049, Val Acc = 76.48%\n",
      "Epoch 211: Train Loss = 0.3394, Train Acc = 91.50% | Val Loss = 0.8058, Val Acc = 76.50%\n",
      "Epoch 212: Train Loss = 0.3387, Train Acc = 91.52% | Val Loss = 0.8056, Val Acc = 76.52%\n",
      "Epoch 213: Train Loss = 0.3379, Train Acc = 91.53% | Val Loss = 0.8060, Val Acc = 76.54%\n",
      "Epoch 214: Train Loss = 0.3370, Train Acc = 91.58% | Val Loss = 0.8067, Val Acc = 76.44%\n",
      "Epoch 215: Train Loss = 0.3364, Train Acc = 91.61% | Val Loss = 0.8069, Val Acc = 76.52%\n",
      "Epoch 216: Train Loss = 0.3356, Train Acc = 91.61% | Val Loss = 0.8070, Val Acc = 76.60%\n",
      "Epoch 217: Train Loss = 0.3349, Train Acc = 91.70% | Val Loss = 0.8071, Val Acc = 76.56%\n",
      "Epoch 218: Train Loss = 0.3341, Train Acc = 91.62% | Val Loss = 0.8073, Val Acc = 76.60%\n",
      "Epoch 219: Train Loss = 0.3334, Train Acc = 91.70% | Val Loss = 0.8079, Val Acc = 76.48%\n",
      "Epoch 220: Train Loss = 0.3327, Train Acc = 91.73% | Val Loss = 0.8081, Val Acc = 76.60%\n",
      "Epoch 221: Train Loss = 0.3319, Train Acc = 91.70% | Val Loss = 0.8082, Val Acc = 76.66%\n",
      "Epoch 222: Train Loss = 0.3313, Train Acc = 91.77% | Val Loss = 0.8088, Val Acc = 76.68%\n",
      "Epoch 223: Train Loss = 0.3305, Train Acc = 91.87% | Val Loss = 0.8089, Val Acc = 76.60%\n",
      "Epoch 224: Train Loss = 0.3298, Train Acc = 91.84% | Val Loss = 0.8092, Val Acc = 76.60%\n",
      "Epoch 225: Train Loss = 0.3290, Train Acc = 91.86% | Val Loss = 0.8092, Val Acc = 76.64%\n",
      "Epoch 226: Train Loss = 0.3284, Train Acc = 91.90% | Val Loss = 0.8096, Val Acc = 76.72%\n",
      "Epoch 227: Train Loss = 0.3276, Train Acc = 91.89% | Val Loss = 0.8098, Val Acc = 76.76%\n",
      "Epoch 228: Train Loss = 0.3269, Train Acc = 91.94% | Val Loss = 0.8106, Val Acc = 76.50%\n",
      "Epoch 229: Train Loss = 0.3262, Train Acc = 91.91% | Val Loss = 0.8110, Val Acc = 76.52%\n",
      "Epoch 230: Train Loss = 0.3256, Train Acc = 91.97% | Val Loss = 0.8110, Val Acc = 76.44%\n",
      "Epoch 231: Train Loss = 0.3249, Train Acc = 91.97% | Val Loss = 0.8107, Val Acc = 76.52%\n",
      "Epoch 232: Train Loss = 0.3242, Train Acc = 92.01% | Val Loss = 0.8113, Val Acc = 76.68%\n",
      "Epoch 233: Train Loss = 0.3235, Train Acc = 92.01% | Val Loss = 0.8119, Val Acc = 76.54%\n",
      "Epoch 234: Train Loss = 0.3228, Train Acc = 92.08% | Val Loss = 0.8117, Val Acc = 76.48%\n",
      "Epoch 235: Train Loss = 0.3221, Train Acc = 92.02% | Val Loss = 0.8130, Val Acc = 76.50%\n",
      "Epoch 236: Train Loss = 0.3214, Train Acc = 92.08% | Val Loss = 0.8127, Val Acc = 76.48%\n",
      "Epoch 237: Train Loss = 0.3208, Train Acc = 92.10% | Val Loss = 0.8128, Val Acc = 76.40%\n",
      "Epoch 238: Train Loss = 0.3202, Train Acc = 92.14% | Val Loss = 0.8123, Val Acc = 76.66%\n",
      "Epoch 239: Train Loss = 0.3195, Train Acc = 92.15% | Val Loss = 0.8138, Val Acc = 76.66%\n",
      "Epoch 240: Train Loss = 0.3188, Train Acc = 92.16% | Val Loss = 0.8136, Val Acc = 76.52%\n",
      "Epoch 241: Train Loss = 0.3181, Train Acc = 92.21% | Val Loss = 0.8138, Val Acc = 76.56%\n",
      "Epoch 242: Train Loss = 0.3174, Train Acc = 92.21% | Val Loss = 0.8140, Val Acc = 76.58%\n",
      "Epoch 243: Train Loss = 0.3169, Train Acc = 92.23% | Val Loss = 0.8142, Val Acc = 76.54%\n",
      "Epoch 244: Train Loss = 0.3162, Train Acc = 92.24% | Val Loss = 0.8144, Val Acc = 76.52%\n",
      "Epoch 245: Train Loss = 0.3155, Train Acc = 92.25% | Val Loss = 0.8149, Val Acc = 76.50%\n",
      "Epoch 246: Train Loss = 0.3149, Train Acc = 92.30% | Val Loss = 0.8152, Val Acc = 76.48%\n",
      "Epoch 247: Train Loss = 0.3143, Train Acc = 92.33% | Val Loss = 0.8158, Val Acc = 76.52%\n",
      "Epoch 248: Train Loss = 0.3137, Train Acc = 92.36% | Val Loss = 0.8165, Val Acc = 76.50%\n",
      "Epoch 249: Train Loss = 0.3130, Train Acc = 92.40% | Val Loss = 0.8160, Val Acc = 76.52%\n",
      "Epoch 250: Train Loss = 0.3124, Train Acc = 92.41% | Val Loss = 0.8160, Val Acc = 76.42%\n",
      "Epoch 251: Train Loss = 0.3117, Train Acc = 92.44% | Val Loss = 0.8167, Val Acc = 76.26%\n",
      "Epoch 252: Train Loss = 0.3112, Train Acc = 92.47% | Val Loss = 0.8168, Val Acc = 76.52%\n",
      "Epoch 253: Train Loss = 0.3104, Train Acc = 92.49% | Val Loss = 0.8169, Val Acc = 76.48%\n",
      "Epoch 254: Train Loss = 0.3099, Train Acc = 92.48% | Val Loss = 0.8171, Val Acc = 76.50%\n",
      "Epoch 255: Train Loss = 0.3093, Train Acc = 92.48% | Val Loss = 0.8175, Val Acc = 76.52%\n",
      "Epoch 256: Train Loss = 0.3087, Train Acc = 92.48% | Val Loss = 0.8183, Val Acc = 76.46%\n",
      "Epoch 257: Train Loss = 0.3081, Train Acc = 92.57% | Val Loss = 0.8185, Val Acc = 76.64%\n",
      "Epoch 258: Train Loss = 0.3075, Train Acc = 92.56% | Val Loss = 0.8185, Val Acc = 76.44%\n",
      "Epoch 259: Train Loss = 0.3069, Train Acc = 92.61% | Val Loss = 0.8188, Val Acc = 76.42%\n",
      "Epoch 260: Train Loss = 0.3062, Train Acc = 92.61% | Val Loss = 0.8189, Val Acc = 76.48%\n",
      "Epoch 261: Train Loss = 0.3058, Train Acc = 92.64% | Val Loss = 0.8195, Val Acc = 76.56%\n",
      "Epoch 262: Train Loss = 0.3051, Train Acc = 92.64% | Val Loss = 0.8200, Val Acc = 76.60%\n",
      "Epoch 263: Train Loss = 0.3045, Train Acc = 92.69% | Val Loss = 0.8197, Val Acc = 76.54%\n",
      "Epoch 264: Train Loss = 0.3039, Train Acc = 92.66% | Val Loss = 0.8205, Val Acc = 76.50%\n",
      "Epoch 265: Train Loss = 0.3034, Train Acc = 92.70% | Val Loss = 0.8212, Val Acc = 76.54%\n",
      "Epoch 266: Train Loss = 0.3027, Train Acc = 92.75% | Val Loss = 0.8205, Val Acc = 76.54%\n",
      "Epoch 267: Train Loss = 0.3022, Train Acc = 92.72% | Val Loss = 0.8209, Val Acc = 76.48%\n",
      "Epoch 268: Train Loss = 0.3016, Train Acc = 92.73% | Val Loss = 0.8216, Val Acc = 76.48%\n",
      "Epoch 269: Train Loss = 0.3010, Train Acc = 92.79% | Val Loss = 0.8222, Val Acc = 76.54%\n",
      "Epoch 270: Train Loss = 0.3005, Train Acc = 92.80% | Val Loss = 0.8222, Val Acc = 76.58%\n",
      "Epoch 271: Train Loss = 0.2999, Train Acc = 92.75% | Val Loss = 0.8222, Val Acc = 76.54%\n",
      "Epoch 272: Train Loss = 0.2993, Train Acc = 92.83% | Val Loss = 0.8229, Val Acc = 76.52%\n",
      "Epoch 273: Train Loss = 0.2988, Train Acc = 92.85% | Val Loss = 0.8233, Val Acc = 76.40%\n",
      "Epoch 274: Train Loss = 0.2982, Train Acc = 92.86% | Val Loss = 0.8233, Val Acc = 76.50%\n",
      "Epoch 275: Train Loss = 0.2975, Train Acc = 92.90% | Val Loss = 0.8238, Val Acc = 76.56%\n",
      "Epoch 276: Train Loss = 0.2971, Train Acc = 92.91% | Val Loss = 0.8244, Val Acc = 76.50%\n",
      "Epoch 277: Train Loss = 0.2965, Train Acc = 92.95% | Val Loss = 0.8246, Val Acc = 76.56%\n",
      "Epoch 278: Train Loss = 0.2960, Train Acc = 92.94% | Val Loss = 0.8244, Val Acc = 76.62%\n",
      "Epoch 279: Train Loss = 0.2954, Train Acc = 93.00% | Val Loss = 0.8245, Val Acc = 76.42%\n",
      "Epoch 280: Train Loss = 0.2949, Train Acc = 92.96% | Val Loss = 0.8247, Val Acc = 76.50%\n",
      "Epoch 281: Train Loss = 0.2943, Train Acc = 92.98% | Val Loss = 0.8258, Val Acc = 76.66%\n",
      "Epoch 282: Train Loss = 0.2938, Train Acc = 93.03% | Val Loss = 0.8257, Val Acc = 76.52%\n",
      "Epoch 283: Train Loss = 0.2933, Train Acc = 93.05% | Val Loss = 0.8261, Val Acc = 76.50%\n",
      "Epoch 284: Train Loss = 0.2927, Train Acc = 93.04% | Val Loss = 0.8267, Val Acc = 76.50%\n",
      "Epoch 285: Train Loss = 0.2922, Train Acc = 93.10% | Val Loss = 0.8261, Val Acc = 76.56%\n",
      "Epoch 286: Train Loss = 0.2916, Train Acc = 93.09% | Val Loss = 0.8262, Val Acc = 76.48%\n",
      "Epoch 287: Train Loss = 0.2911, Train Acc = 93.11% | Val Loss = 0.8271, Val Acc = 76.44%\n",
      "Epoch 288: Train Loss = 0.2907, Train Acc = 93.13% | Val Loss = 0.8269, Val Acc = 76.48%\n",
      "Epoch 289: Train Loss = 0.2901, Train Acc = 93.10% | Val Loss = 0.8274, Val Acc = 76.48%\n",
      "Epoch 290: Train Loss = 0.2896, Train Acc = 93.13% | Val Loss = 0.8282, Val Acc = 76.48%\n",
      "Epoch 291: Train Loss = 0.2890, Train Acc = 93.14% | Val Loss = 0.8277, Val Acc = 76.62%\n",
      "Epoch 292: Train Loss = 0.2885, Train Acc = 93.21% | Val Loss = 0.8283, Val Acc = 76.56%\n",
      "Epoch 293: Train Loss = 0.2880, Train Acc = 93.19% | Val Loss = 0.8288, Val Acc = 76.48%\n",
      "Epoch 294: Train Loss = 0.2875, Train Acc = 93.20% | Val Loss = 0.8291, Val Acc = 76.54%\n",
      "Epoch 295: Train Loss = 0.2870, Train Acc = 93.24% | Val Loss = 0.8290, Val Acc = 76.40%\n",
      "Epoch 296: Train Loss = 0.2864, Train Acc = 93.23% | Val Loss = 0.8289, Val Acc = 76.50%\n",
      "Epoch 297: Train Loss = 0.2859, Train Acc = 93.26% | Val Loss = 0.8300, Val Acc = 76.44%\n",
      "Epoch 298: Train Loss = 0.2854, Train Acc = 93.26% | Val Loss = 0.8300, Val Acc = 76.38%\n",
      "Epoch 299: Train Loss = 0.2850, Train Acc = 93.27% | Val Loss = 0.8304, Val Acc = 76.56%\n",
      "Epoch 300: Train Loss = 0.2845, Train Acc = 93.31% | Val Loss = 0.8308, Val Acc = 76.42%\n",
      "\n",
      "✅ Test Accuracy: 75.20%\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "cifar10 = torch.load('cifar100_swin_features.pt')\n",
    "# Config\n",
    "batch_size = 64\n",
    "epochs = 300\n",
    "lr = 0.01\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "# pca = PCA(0.75)\n",
    "# cifar10['features'] = torch.tensor(pca.fit_transform(cifar10['features'].numpy()))\n",
    "print(min(cifar10['labels']), max(cifar10['labels']))\n",
    "# Model\n",
    "cifar10_model = torch.nn.Sequential(\n",
    "\ttorch.nn.Linear(cifar10['features'].shape[1], 100),\n",
    "\t# torch.nn.ReLU(),\n",
    "\t# torch.nn.BatchNorm1d(256),\n",
    "\t# torch.nn.Linear(256, 10)\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(cifar10_model.parameters(), lr=lr)#, weight_decay=0.02)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Load data\n",
    "X = cifar10['features']\n",
    "y = cifar10['labels'].long()\n",
    "\n",
    "# Dataset\n",
    "full_dataset = TensorDataset(X, y)\n",
    "\n",
    "# Split sizes\n",
    "total = len(full_dataset)\n",
    "train_size = int(0.8 * total)\n",
    "val_size = int(0.1 * total)\n",
    "test_size = total - train_size - val_size\n",
    "\n",
    "train_set, val_set, test_set = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "\tcifar10_model.train()\n",
    "\ttotal_loss = 0\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\n",
    "\tfor xb, yb in train_loader:\n",
    "\t\txb, yb = xb.to(device), yb.to(device)\n",
    "\t\toutputs = cifar10_model(xb)\n",
    "\t\tloss = criterion(outputs, yb)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\ttotal_loss += loss.item() * yb.size(0)\n",
    "\t\t_, preds = torch.max(outputs, 1)\n",
    "\t\tcorrect += (preds == yb).sum().item()\n",
    "\t\ttotal += yb.size(0)\n",
    "\n",
    "\ttrain_acc = correct / total\n",
    "\ttrain_loss = total_loss / total\n",
    "\n",
    "\t# Validation\n",
    "\tcifar10_model.eval()\n",
    "\tval_correct = 0\n",
    "\tval_total = 0\n",
    "\tval_loss = 0\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tfor xb, yb in val_loader:\n",
    "\t\t\txb, yb = xb.to(device), yb.to(device)\n",
    "\t\t\toutputs = cifar10_model(xb)\n",
    "\t\t\tloss = criterion(outputs, yb)\n",
    "\n",
    "\t\t\tval_loss += loss.item() * yb.size(0)\n",
    "\t\t\t_, preds = torch.max(outputs, 1)\n",
    "\t\t\tval_correct += (preds == yb).sum().item()\n",
    "\t\t\tval_total += yb.size(0)\n",
    "\n",
    "\tval_acc = val_correct / val_total\n",
    "\tval_loss /= val_total\n",
    "\n",
    "\tprint(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Train Acc = {train_acc:.2%} | Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.2%}\")\n",
    "\n",
    "# Final test set evaluation\n",
    "cifar10_model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\tfor xb, yb in test_loader:\n",
    "\t\txb, yb = xb.to(device), yb.to(device)\n",
    "\t\toutputs = cifar10_model(xb)\n",
    "\t\t_, preds = torch.max(outputs, 1)\n",
    "\t\ttest_correct += (preds == yb).sum().item()\n",
    "\t\ttest_total += yb.size(0)\n",
    "\n",
    "test_acc = test_correct / test_total\n",
    "print(f\"\\n✅ Test Accuracy: {test_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.2294, Test Loss = 0.1165, Accuracy = 0.9635\n",
      "Epoch 2: Train Loss = 0.0925, Test Loss = 0.1266, Accuracy = 0.9593\n",
      "Epoch 3: Train Loss = 0.0637, Test Loss = 0.0829, Accuracy = 0.9755\n",
      "Epoch 4: Train Loss = 0.0498, Test Loss = 0.0843, Accuracy = 0.9734\n",
      "Epoch 5: Train Loss = 0.0411, Test Loss = 0.0675, Accuracy = 0.9800\n",
      "Epoch 6: Train Loss = 0.0321, Test Loss = 0.0831, Accuracy = 0.9785\n",
      "Epoch 7: Train Loss = 0.0290, Test Loss = 0.0757, Accuracy = 0.9789\n",
      "Epoch 8: Train Loss = 0.0254, Test Loss = 0.0925, Accuracy = 0.9764\n",
      "Epoch 9: Train Loss = 0.0225, Test Loss = 0.0897, Accuracy = 0.9778\n",
      "Epoch 10: Train Loss = 0.0176, Test Loss = 0.0950, Accuracy = 0.9783\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Define basic transform: convert images to tensors and normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "\tnn.Flatten(),                     # Flatten 28x28 -> 784\n",
    "\tnn.Linear(784, 256),\n",
    "\tnn.ReLU(),\n",
    "\tnn.Linear(256, 128),\n",
    "\tnn.ReLU(),\n",
    "\tnn.Linear(128, 10)               # 10 output classes for MNIST\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# Load MNIST train/test datasets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "# DataLoaders for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (x, y) in enumerate(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            total_loss += criterion(output, y).item()\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(y).sum().item()\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    return total_loss / len(loader), accuracy\n",
    "\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Test Loss = {test_loss:.4f}, Accuracy = {test_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Crypten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
